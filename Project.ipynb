{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  5907\n",
      "Sample data: ['X_Train/0.jpg', 'X_Train/1.jpg', 'X_Train/2.jpg', 'X_Train/3.jpg', 'X_Train/4.jpg'] ['1', '1', '0', '0', '0']\n",
      "Descriptors computed!\n",
      "Training completed!\n",
      "Sample Predict Results:  [array(['1'], \n",
      "      dtype='<U1'), array(['1'], \n",
      "      dtype='<U1'), array(['1'], \n",
      "      dtype='<U1'), array(['1'], \n",
      "      dtype='<U1'), array(['1'], \n",
      "      dtype='<U1'), array(['1'], \n",
      "      dtype='<U1'), array(['1'], \n",
      "      dtype='<U1'), array(['0'], \n",
      "      dtype='<U1'), array(['0'], \n",
      "      dtype='<U1'), array(['1'], \n",
      "      dtype='<U1')]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cats vs. Dogs classification\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import glob\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Get image paths and the corresponding labels for the Training set.\n",
    "# Return: list of path str, list of label str\n",
    "def getTrainImg():\n",
    "    image_paths = []\n",
    "    image_labels = []\n",
    "    Y_Train = None\n",
    "    \n",
    "    # Read lines from the Y_Train with label and name info, into dict format\n",
    "    with open('Y_Train.csv', 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        Y_Train = list(reader)\n",
    "\n",
    "    # extract path and labels\n",
    "    for image in Y_Train:\n",
    "        # folder + name = path\n",
    "        image_paths.append('X_Train/'+image['Image'])\n",
    "        image_labels.append(image['Label'])\n",
    "        \n",
    "    print('Number of images: ', len(image_paths))\n",
    "    print('Sample data:', image_paths[:5],image_labels[:5])\n",
    "\n",
    "    return image_paths, image_labels\n",
    "\n",
    "# Calculate descriptors for each image, and save the descriptor list into 'descriptors.p'.\n",
    "# Input: list of str\n",
    "# Return: void\n",
    "def getDes(image_paths):\n",
    "    descriptors = []\n",
    "    for path in image_paths:\n",
    "        im = cv2.imread(path)\n",
    "        _, des = sift.detectAndCompute(im,None)\n",
    "        descriptors.append(des)\n",
    "    pickle.dump(descriptors, open(\"descriptors.p\", \"wb\"))\n",
    "    print('Descriptors computed!')\n",
    "\n",
    "# Compute the corresponding feature in the BoW vocabulary for the image in path.\n",
    "# Input: BoW extractor, str of image path\n",
    "# Return: list of features\n",
    "def getImageData(bow_extract, path):\n",
    "    im = cv2.imread(path)\n",
    "    features = bow_extract.compute(im, sift.detect(im))\n",
    "    return features\n",
    "\n",
    "# Train the linearSVC by kmeans bag of words.\n",
    "# input: list of label str, list of path str\n",
    "# return: void\n",
    "def train(image_labels, image_paths):\n",
    "    # Load precalculated descriptor for all training images\n",
    "    descriptors = pickle.load(open(\"descriptors.p\", \"rb\"))\n",
    "    # Initialize Brute Force Matcher\n",
    "    matcher = cv2.BFMatcher()\n",
    "    # Initialize Bag of Words descriptor extractor\n",
    "    bow_extract  = cv2.BOWImgDescriptorExtractor(sift,matcher)\n",
    "    # Initialize bag of words k-means trainer, with 50 clusters\n",
    "    bow_train = cv2.BOWKMeansTrainer(50)\n",
    "    # Add all training descriptors into the bow k-means trainer\n",
    "    for des in descriptors:\n",
    "        bow_train.add(des)\n",
    "        \n",
    "    # Cluster the descriptors into 50 vocabularies\n",
    "    voc = bow_train.cluster()\n",
    "    # Set these vocabularies to the BoW descriptor extractor\n",
    "    bow_extract.setVocabulary(voc)\n",
    "    \n",
    "    # Describe each training image with the 50 clusted vocabularies\n",
    "    traindata = []\n",
    "    for path in image_paths:\n",
    "        features = getImageData(bow_extract, path)\n",
    "        traindata.extend(features)\n",
    "    \n",
    "    # Initialize Linear Support Vector Classification\n",
    "    clf = svm.LinearSVC()\n",
    "    # Train the LinearSVC classifier by fitting the image words according to their labels\n",
    "    clf.fit(traindata, np.array(image_labels))\n",
    "    # Save the trained linearSVC classifier and the vocabularies into 'vocabulary.p'\n",
    "    pickle.dump((voc,clf), open(\"vocabulary.p\", \"wb\"))\n",
    "    print('Training completed!')\n",
    "\n",
    "\n",
    "# Predicting the test set using the trained linearSVC\n",
    "# return: list of predicted labels\n",
    "def predict():\n",
    "    # Load the vocabulary and the trained linearSVC classifier\n",
    "    voc,clf = pickle.load(open(\"vocabulary.p\", \"rb\"))\n",
    "    # Initialize brute force matcher\n",
    "    matcher = cv2.BFMatcher()\n",
    "    # initialize the bag of word descriptor extractor\n",
    "    bow_extract = cv2.BOWImgDescriptorExtractor(sift, matcher)\n",
    "    # set BoW extractor vocabulary using the previously loaded vocabulary\n",
    "    bow_extract.setVocabulary(voc)\n",
    "\n",
    "    # get a list of all pathes under the X_Test folder\n",
    "    test_paths = glob.glob('X_Test/*.jpg')\n",
    "    \n",
    "    test_results = []\n",
    "    for path in test_paths:\n",
    "        # Describe each test image using the BoW extractor with the 50 clusted vocabularies\n",
    "        features = getImageData(bow_extract, path)\n",
    "        # Predict which of the two labels should each image belong to, using linearSVC classifier\n",
    "        prediction = clf.predict(features)\n",
    "        # put every predicted result into a list\n",
    "        test_results.append(prediction)  \n",
    "    \n",
    "    # write the predicted results into 'Y_Test.csv'\n",
    "    with open('Y_Test.csv', 'w') as csvfile:\n",
    "        fieldnames = ['Image', 'Label']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for path, label in zip(test_paths, test_results):\n",
    "            # the path[7:] is used to remove the 'X_Test/' folder name from the image path\n",
    "            writer.writerow({'Image': path[7:], 'Label': label[0]})\n",
    "    \n",
    "    # The result value is only for display purpose\n",
    "    return test_results\n",
    "\n",
    "\n",
    "\"\"\"main\"\"\"\n",
    "# Initiate SIFT detector with 100 top feature threshold\n",
    "sift = cv2.xfeatures2d.SIFT_create(100)\n",
    "\n",
    "# Note: the following three steps can be executed seperately\n",
    "'''1. calculate descriptors'''\n",
    "image_paths, image_labels = getTrainImg()\n",
    "getDes(image_paths) # a temporary data will be saved in 'descriptor.p' \n",
    "\n",
    "'''2. Train'''\n",
    "image_paths, image_labels = getTrainImg()\n",
    "train(image_labels, image_paths) # a temporary data will be saved in 'vocabulary.p' \n",
    "\n",
    "'''3. Predict''' # The complete prediction result is saved in 'Y_Test.csv'\n",
    "print('Sample Predict Results: ', predict()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Image': '0.jpg', 'Label': '1'}, {'Image': '1.jpg', 'Label': '1'}, {'Image': '2.jpg', 'Label': '1'}, {'Image': '3.jpg', 'Label': '1'}, {'Image': '4.jpg', 'Label': '0'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Rearrange result file\"\"\"\n",
    "#This Block is used to arrange the result data in the 'Y_Test.csv' into asending order by file name\n",
    "import csv\n",
    "\n",
    "# read the result file with name and label\n",
    "Y_Test = None\n",
    "with open('Y_Test.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    Y_Test = list(reader)\n",
    "\n",
    "for Y in Y_Test:\n",
    "    # remove '.jpg' and cast to int\n",
    "    Y['Image'] = int(Y['Image'][:-4])\n",
    "\n",
    "# sort by key = 'image'\n",
    "Y_Test.sort(key=lambda item:item['Image'])\n",
    "\n",
    "for Y in Y_Test:\n",
    "    # cast back to str and add back '.jpg'\n",
    "    Y['Image'] = str(Y['Image']) + '.jpg'\n",
    "\n",
    "# write the arranged result back into the file Y_Test.csv\n",
    "with open('Y_Test.csv', 'w') as csvfile:\n",
    "    fieldnames = ['Image', 'Label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(Y_Test)\n",
    "\n",
    "print('Arranged sample output: ',Y_Test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
